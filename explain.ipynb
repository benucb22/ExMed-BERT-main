{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c4f8fd",
   "metadata": {},
   "source": [
    "# ExMed-BERT Data Preparation for Pretraining\n",
    "\n",
    "This notebook provides a detailed walkthrough of how patient data is prepared for pretraining a BERT-style model using the ExMed-BERT framework. It is designed for users who are new to the codebase and want to understand the data pipeline, encoding strategies, and the rationale behind each step.\n",
    "\n",
    "We will cover:\n",
    "- The purpose and structure of the main classes involved (e.g., `CodeDict`, `AgeDict`, `Patient`, `PatientDataset`)\n",
    "- How medical codes and patient attributes are encoded\n",
    "- How patient data is processed and masked for model input\n",
    "- How a dataset is constructed and saved for pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b57a7",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "We begin by importing the necessary modules and ensuring the ExMed-BERT package is available for import. This includes adding the package directory to the Python path and importing PyTorch for tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0213b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\E648736\\AppData\\Local\\anaconda3\\envs\\exmed-bert\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "# Add the ExMed-BERT package to Python path for imports\n",
    "sys.path.append('./ExMed-BERT-main')\n",
    "\n",
    "import torch  # PyTorch is used for tensor operations and model input formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9703e8",
   "metadata": {},
   "source": [
    "## 2. Encoding Classes: Dictionaries for Medical Data\n",
    "\n",
    "ExMed-BERT uses specialized dictionary classes to encode various types of patient data into integer IDs suitable for model input. These include:\n",
    "- `CodeDict`: Handles medical codes (ICD, PheWAS, RxNorm, ATC) and their mappings.\n",
    "- `AgeDict`: Bins and encodes patient ages.\n",
    "- `SexDict`: Encodes sex/gender.\n",
    "- `StateDict`: Encodes US state information.\n",
    "- `EndpointDict`: Encodes endpoint labels for classification tasks.\n",
    "\n",
    "Let's import these classes and briefly describe their roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7c75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exmed_bert.data.encoding import (\n",
    "    AgeDict,     # Handles age binning and encoding\n",
    "    CodeDict,    # Handles medical codes (ICD, PheWAS, RxNorm, ATC)\n",
    "    SexDict,     # Handles sex/gender encoding\n",
    "    StateDict,   # Handles US state encoding\n",
    "    DICT_DEFAULTS,  # Default tokens (e.g., PAD, UNK, MASK)\n",
    "    EndpointDict # Handles endpoint label encoding (e.g., for classification tasks)\n",
    ")\n",
    "from exmed_bert.data.patient import Patient  # Main class for patient sequence processing\n",
    "from exmed_bert.data.dataset import PatientDataset  # Dataset class for batching patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2389ea",
   "metadata": {},
   "source": [
    "### What do these classes do?\n",
    "- **CodeDict**: Maps raw medical codes (diagnoses, drugs) to integer IDs, handles code normalization (e.g., mapping RxNorm to ATC, ICD to PheWAS), and provides decoding for interpretability.\n",
    "- **AgeDict**: Bins ages (e.g., by year) and encodes them as IDs.\n",
    "- **SexDict**: Encodes sex/gender as IDs.\n",
    "- **StateDict**: Encodes US state abbreviations as IDs.\n",
    "- **EndpointDict**: Encodes outcome labels for supervised tasks.\n",
    "\n",
    "These dictionaries ensure that all categorical data is consistently mapped to integer IDs for model input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197c94e",
   "metadata": {},
   "source": [
    "## 3. Example Code Dictionaries and Mappings\n",
    "\n",
    "For demonstration, we define small example sets of codes and mappings. In real applications, these would be much larger and loaded from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19e7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATC (Anatomical Therapeutic Chemical) codes for medications\n",
    "atc_codes = [\n",
    "    'A01AA01', 'B01AC06', 'C09AA05', 'D05AX02', 'E03AA01', 'F01BA01', 'G04BE03'\n",
    "]\n",
    "\n",
    "# PheWAS (Phenome Wide Association Study) codes for diagnoses\n",
    "phewas_codes = [\n",
    "    '008', '250', '401.1', '530.11', '715.2', '272.1', '585.3'\n",
    "]\n",
    "\n",
    "# Mapping from RxNorm (prescription) to ATC codes\n",
    "rx_to_atc_map = {\n",
    "    '860975': 'A01AA01',\n",
    "    '197361': 'B01AC06',\n",
    "    '123456': 'C09AA05',\n",
    "    '654321': 'D05AX02',\n",
    "    '789012': 'E03AA01',\n",
    "    '345678': 'F01BA01',\n",
    "    '987654': 'G04BE03'\n",
    "}\n",
    "\n",
    "# Mapping from ICD-10 to PheWAS codes\n",
    "icd_to_phewas_map = {\n",
    "    'I10': '401.1',\n",
    "    'E11.9': '250',\n",
    "    'Z51.11': '008',\n",
    "    'K21.0': '530.11',\n",
    "    'M17.9': '715.2',\n",
    "    'E78.5': '272.1',\n",
    "    'N18.3': '585.3'\n",
    "}\n",
    "\n",
    "# List of US states for state encoding\n",
    "state_list = ['CA', 'NY', 'TX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3c4c2",
   "metadata": {},
   "source": [
    "## 4. Initializing Encoding Dictionaries\n",
    "\n",
    "We now create the encoding dictionary objects. These will be used to map all patient data to integer IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2562862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code dictionary for medical codes\n",
    "code_dict = CodeDict(\n",
    "    atc_codes=atc_codes,\n",
    "    phewas_codes=phewas_codes,\n",
    "    rx_to_atc_map=rx_to_atc_map,\n",
    "    icd_to_phewas_map=icd_to_phewas_map\n",
    ")\n",
    "\n",
    "# Age dictionary for binning and encoding ages (by year)\n",
    "age_dict = AgeDict(max_age=90, min_age=0, binsize=1)\n",
    "# Convert the age_dict's vocabulary to integers for consistency\n",
    "age_dict.vocab = [str(int(float(age))) if age not in DICT_DEFAULTS else age for age in age_dict.vocab]\n",
    "age_dict.labels_to_id = {(str(int(float(label))) if label not in DICT_DEFAULTS else label): idx \n",
    "                        for label, idx in age_dict.labels_to_id.items()}\n",
    "age_dict.ids_to_label = {idx: (str(int(float(label))) if label not in DICT_DEFAULTS else label)\n",
    "                        for idx, label in age_dict.ids_to_label.items()}\n",
    "\n",
    "# Sex dictionary\n",
    "sex_dict = SexDict(sex=['MALE', 'FEMALE'])\n",
    "\n",
    "# State dictionary\n",
    "state_dict = StateDict(states=state_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64039ee",
   "metadata": {},
   "source": [
    "## 5. Example Patient Data\n",
    "\n",
    "We create example patients with expanded medical histories. Each patient is represented as a dictionary with diagnoses, drugs, dates, and demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194df3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = [\n",
    "    {\n",
    "        'patient_id': 12345,\n",
    "        'diagnoses': ['I10', 'E11.9', 'Z51.11', 'K21.0', 'M17.9', 'E78.5', 'N18.3'],\n",
    "        'diagnosis_dates': [\n",
    "            date(2021, 3, 15), date(2022, 3, 15), date(2023, 4, 20),\n",
    "            date(2024, 5, 1), date(2025, 5, 10), date(2025, 6, 5), date(2025, 7, 12)\n",
    "        ],\n",
    "        'drugs': ['860975', '197361', '197361', '654321', '789012', '345678', '987654'],\n",
    "        'prescription_dates': [\n",
    "            date(2021, 3, 16), date(2022, 3, 16), date(2023, 4, 21),\n",
    "            date(2024, 5, 2), date(2025, 5, 11), date(2025, 6, 6), date(2025, 7, 13)\n",
    "        ],\n",
    "        'birth_year': 2004,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'CA'\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 67890,\n",
    "        'diagnoses': ['E11.9', 'I10', 'K21.0', 'M17.9', 'E78.5', 'N18.3', 'Z51.11'],\n",
    "        'diagnosis_dates': [\n",
    "            date(2021, 5, 1), date(2022, 5, 15), date(2023, 5, 20),\n",
    "            date(2024, 6, 1), date(2025, 6, 10), date(2025, 7, 5), date(2025, 8, 12)\n",
    "        ],\n",
    "        'drugs': ['123456', '860975', '654321', '789012', '345678', '987654', '197361'],\n",
    "        'prescription_dates': [\n",
    "            date(2021, 5, 2), date(2022, 5, 16), date(2023, 5, 21),\n",
    "            date(2024, 6, 2), date(2025, 6, 11), date(2025, 7, 6), date(2025, 8, 13)\n",
    "        ],\n",
    "        'birth_year': 1960,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'NY'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1399813",
   "metadata": {},
   "source": [
    "## 6. Patient Object: Encoding and Processing\n",
    "\n",
    "The `Patient` class takes a patient's raw data and encodes it using the dictionaries above. It also handles masking (for masked language modeling), sequence splitting, and other preprocessing steps.\n",
    "\n",
    "Let's process each patient and inspect the encoded and decoded outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9501db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input_ids: tensor([ 2, 15,  3,  6,  3, 14,  3,  7,  3,  4,  3,  7,  3, 16,  3,  9,  3, 17,\n",
      "         3, 10,  3, 18,  3, 11,  3, 19,  3, 12,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "  entity_ids: tensor([0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1,\n",
      "        0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  sex_ids: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  position_ids: tensor([ 1,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,\n",
      "         9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "  state_ids: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  age_ids: tensor([19, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "  code_labels: tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100,   13, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100,   10, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100])\n",
      "  input_ids (codes): ['CLS', '401.1', 'SEP', 'A01AA01', 'SEP', '250', 'SEP', 'B01AC06', 'SEP', 'MASK', 'SEP', 'B01AC06', 'SEP', '530.11', 'SEP', 'D05AX02', 'SEP', '715.2', 'SEP', 'E03AA01', 'SEP', '272.1', 'SEP', 'F01BA01', 'SEP', '585.3', 'SEP', 'G04BE03', 'SEP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  sex_ids: ['MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  state_ids: ['CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'CA', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  age_ids: ['17', '17', '17', '17', '17', '18', '18', '18', '18', '19', '19', '19', '19', '20', '20', '20', '20', '21', '21', '21', '21', '21', '21', '21', '21', '21', '21', '21', '21', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  entity_ids: ['default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']\n",
      "  code_labels: [None, None, None, None, None, None, None, None, None, '008', None, None, None, None, None, None, None, None, None, 'E03AA01', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "      codes   sex position entity_ids code_label state  age\n",
      "0       CLS  MALE        1    default       None    CA   17\n",
      "1     401.1  MALE        1     phewas       None    CA   17\n",
      "2       SEP  MALE        1    default       None    CA   17\n",
      "3   A01AA01  MALE        2        atc       None    CA   17\n",
      "4       SEP  MALE        2    default       None    CA   17\n",
      "5       250  MALE        3     phewas       None    CA   18\n",
      "6       SEP  MALE        3    default       None    CA   18\n",
      "7   B01AC06  MALE        4        atc       None    CA   18\n",
      "8       SEP  MALE        4    default       None    CA   18\n",
      "9      MASK  MALE        5     phewas       None    CA   19\n",
      "10      SEP  MALE        5    default       None    CA   19\n",
      "11  B01AC06  MALE        6        atc       None    CA   19\n",
      "12      SEP  MALE        6    default       None    CA   19\n",
      "13   530.11  MALE        7     phewas       None    CA   20\n",
      "14      SEP  MALE        7    default       None    CA   20\n",
      "15  D05AX02  MALE        8        atc       None    CA   20\n",
      "16      SEP  MALE        8    default       None    CA   20\n",
      "17     MASK  MALE        9     phewas      715.2    CA   21\n",
      "18      SEP  MALE        9    default       None    CA   21\n",
      "19  E03AA01  MALE       10        atc       None    CA   21\n",
      "20      SEP  MALE       10    default       None    CA   21\n",
      "21    272.1  MALE       11     phewas       None    CA   21\n",
      "22      SEP  MALE       11    default       None    CA   21\n",
      "23  F01BA01  MALE       12        atc       None    CA   21\n",
      "24      SEP  MALE       12    default       None    CA   21\n",
      "25    585.3  MALE       13     phewas       None    CA   21\n",
      "26      SEP  MALE       13    default       None    CA   21\n",
      "27     MASK  MALE       14        atc    G04BE03    CA   21\n",
      "28      SEP  MALE       14    default       None    CA   21\n",
      "29      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "30      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "31      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "32      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "33      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "34      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "35      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "36      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "37      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "38      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "39      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "40      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "41      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "42      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "43      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "44      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "45      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "46      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "47      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "48      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "49      PAD   PAD      PAD    default       None   PAD  PAD\n",
      "  input_ids: tensor([ 2, 14,  3,  8,  3, 15,  3,  6,  3, 16,  3,  9,  3, 17,  3,  4,  3, 18,\n",
      "         3, 11,  3, 19,  3, 12,  3, 13,  3,  7,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "  entity_ids: tensor([0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1,\n",
      "        0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  sex_ids: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  position_ids: tensor([ 1,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,\n",
      "         9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "  state_ids: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "  age_ids: tensor([63, 63, 63, 63, 63, 64, 64, 64, 64, 65, 65, 65, 65, 66, 66, 66, 66, 67,\n",
      "        67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "  code_labels: tensor([-100,   14, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,   10, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100])\n",
      "  input_ids (codes): ['CLS', '250', 'SEP', 'C09AA05', 'SEP', '401.1', 'SEP', 'A01AA01', 'SEP', '530.11', 'SEP', 'D05AX02', 'SEP', '715.2', 'SEP', 'MASK', 'SEP', '272.1', 'SEP', 'F01BA01', 'SEP', '585.3', 'SEP', 'G04BE03', 'SEP', '008', 'SEP', 'B01AC06', 'SEP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  sex_ids: ['FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  state_ids: ['NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'NY', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  age_ids: ['61', '61', '61', '61', '61', '62', '62', '62', '62', '63', '63', '63', '63', '64', '64', '64', '64', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "  entity_ids: ['default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'phewas', 'default', 'atc', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']\n",
      "  code_labels: [None, '250', None, None, None, None, None, None, None, None, None, None, None, None, None, 'E03AA01', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "      codes     sex position entity_ids code_label state  age\n",
      "0       CLS  FEMALE        1    default       None    NY   61\n",
      "1       250  FEMALE        1     phewas       None    NY   61\n",
      "2       SEP  FEMALE        1    default       None    NY   61\n",
      "3   C09AA05  FEMALE        2        atc       None    NY   61\n",
      "4       SEP  FEMALE        2    default       None    NY   61\n",
      "5     401.1  FEMALE        3     phewas       None    NY   62\n",
      "6       SEP  FEMALE        3    default       None    NY   62\n",
      "7   A01AA01  FEMALE        4        atc       None    NY   62\n",
      "8       SEP  FEMALE        4    default       None    NY   62\n",
      "9    530.11  FEMALE        5     phewas       None    NY   63\n",
      "10      SEP  FEMALE        5    default       None    NY   63\n",
      "11  D05AX02  FEMALE        6        atc       None    NY   63\n",
      "12      SEP  FEMALE        6    default       None    NY   63\n",
      "13    715.2  FEMALE        7     phewas       None    NY   64\n",
      "14      SEP  FEMALE        7    default       None    NY   64\n",
      "15     MASK  FEMALE        8        atc       None    NY   64\n",
      "16      SEP  FEMALE        8    default       None    NY   64\n",
      "17    272.1  FEMALE        9     phewas      272.1    NY   65\n",
      "18      SEP  FEMALE        9    default       None    NY   65\n",
      "19     MASK  FEMALE       10        atc    F01BA01    NY   65\n",
      "20      SEP  FEMALE       10    default       None    NY   65\n",
      "21    585.3  FEMALE       11     phewas       None    NY   65\n",
      "22      SEP  FEMALE       11    default       None    NY   65\n",
      "23  G04BE03  FEMALE       12        atc       None    NY   65\n",
      "24      SEP  FEMALE       12    default       None    NY   65\n",
      "25      008  FEMALE       13     phewas       None    NY   65\n",
      "26      SEP  FEMALE       13    default       None    NY   65\n",
      "27  B01AC06  FEMALE       14        atc       None    NY   65\n",
      "28      SEP  FEMALE       14    default       None    NY   65\n",
      "29      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "30      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "31      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "32      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "33      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "34      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "35      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "36      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "37      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "38      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "39      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "40      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "41      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "42      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "43      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "44      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "45      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "46      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "47      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "48      PAD     PAD      PAD    default       None   PAD  PAD\n",
      "49      PAD     PAD      PAD    default       None   PAD  PAD\n"
     ]
    }
   ],
   "source": [
    "for idx, patient_data in enumerate(patients, 1):\n",
    "    try:\n",
    "        patient = Patient(\n",
    "            patient_id=patient_data['patient_id'],\n",
    "            diagnoses=patient_data['diagnoses'],\n",
    "            drugs=patient_data['drugs'],\n",
    "            diagnosis_dates=patient_data['diagnosis_dates'],\n",
    "            prescription_dates=patient_data['prescription_dates'],\n",
    "            birth_year=patient_data['birth_year'],\n",
    "            sex=patient_data['sex'],\n",
    "            patient_state=patient_data['patient_state'],\n",
    "            max_length=50,\n",
    "            code_embed=code_dict,\n",
    "            sex_embed=sex_dict,\n",
    "            age_embed=age_dict,\n",
    "            state_embed=state_dict,\n",
    "            mask_drugs=True,\n",
    "            delete_temporary_variables=True,\n",
    "            split_sequence=True,\n",
    "            drop_duplicates=True,\n",
    "            converted_codes=False,\n",
    "            convert_icd_to_phewas=True,\n",
    "            convert_rxcui_to_atc=True,\n",
    "            keep_min_unmasked=1,\n",
    "            max_masked_tokens=20,\n",
    "            masked_lm_prob=0.15,\n",
    "            truncate='right',\n",
    "            index_date=None,\n",
    "            had_plos=None,\n",
    "            endpoint_labels=patient_data.get('endpoint_labels', None),\n",
    "            dynamic_masking=False,\n",
    "            min_observations=5,\n",
    "            age_usage='year',\n",
    "            use_cls=True,\n",
    "            use_sep=True,\n",
    "            valid_patient=True,\n",
    "            num_visits=None,\n",
    "            combined_length=None,\n",
    "            unpadded_length=None\n",
    "        )\n",
    "\n",
    "        # Get encoded data for model input\n",
    "        model_input = patient.get_patient_data(\n",
    "            evaluate=True,\n",
    "            mask_dynamically=False,\n",
    "            min_unmasked=1,\n",
    "            max_masked=20,\n",
    "            masked_lm_prob=0.15,\n",
    "            mask_drugs=True\n",
    "        )\n",
    "\n",
    "        for k, v in model_input.items():\n",
    "            print(f'  {k}: {v}')\n",
    "        if 'input_ids' in model_input:\n",
    "            print('  input_ids (codes):', code_dict.decode(model_input['input_ids']))\n",
    "        if 'sex_ids' in model_input:\n",
    "            print('  sex_ids:', sex_dict.decode(model_input['sex_ids']))\n",
    "        if 'state_ids' in model_input:\n",
    "            print('  state_ids:', state_dict.decode(model_input['state_ids']))\n",
    "        if 'age_ids' in model_input:\n",
    "            print('  age_ids:', age_dict.decode(model_input['age_ids']))\n",
    "        if 'entity_ids' in model_input:\n",
    "            print('  entity_ids:', [code_dict.ids_to_entity.get(x.item(), 'UNK') for x in model_input['entity_ids']])\n",
    "        if 'code_labels' in model_input:\n",
    "            print('  code_labels:', code_dict.decode(model_input['code_labels']))\n",
    "        df = patient.to_df(\n",
    "            code_embed=code_dict,\n",
    "            age_embed=age_dict,\n",
    "            sex_embed=sex_dict,\n",
    "            state_embed=state_dict,\n",
    "            dynamic_masking=True,\n",
    "            mask_drugs=True,\n",
    "            min_unmasked=1,\n",
    "            max_masked=20,\n",
    "            masked_lm_prob=0.15\n",
    "        )\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing patient {idx}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1defa",
   "metadata": {},
   "source": [
    "### What happens in this step?\n",
    "- Each patient's data is encoded into integer IDs using the dictionaries.\n",
    "- Masking is applied to some codes for masked language modeling (MLM) pretraining.\n",
    "- The encoded data is ready for input to a BERT-style model.\n",
    "- The decoded output and DataFrame view help with interpretability and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878905d3",
   "metadata": {},
   "source": [
    "## 7. Adding Endpoint Labels for Pretraining\n",
    "\n",
    "For supervised pretraining, we may want to predict clinical endpoints (e.g., Prolonged Length of Stay, 'plos'). We add endpoint labels to each patient and encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae27e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_labels = ['plos']\n",
    "endpoint_dict = EndpointDict(endpoint_labels)\n",
    "\n",
    "# Add a 'plos' label to each patient (for demo, alternate 0/1)\n",
    "for i, patient in enumerate(patients):\n",
    "    patient['endpoint_labels'] = torch.LongTensor([i % 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91f8b9",
   "metadata": {},
   "source": [
    "## 8. Creating Patient Objects with Endpoint Labels\n",
    "\n",
    "We now create `Patient` objects for each patient, including the endpoint labels. These objects are ready for batching into a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7478fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_objs = []\n",
    "for patient_data in patients:\n",
    "    patient_obj = Patient(\n",
    "        patient_id=patient_data['patient_id'],\n",
    "        diagnoses=patient_data['diagnoses'],\n",
    "        drugs=patient_data['drugs'],\n",
    "        diagnosis_dates=patient_data['diagnosis_dates'],\n",
    "        prescription_dates=patient_data['prescription_dates'],\n",
    "        birth_year=patient_data['birth_year'],\n",
    "        sex=patient_data['sex'],\n",
    "        patient_state=patient_data['patient_state'],\n",
    "        max_length=50,\n",
    "        code_embed=code_dict,\n",
    "        sex_embed=sex_dict,\n",
    "        age_embed=age_dict,\n",
    "        state_embed=state_dict,\n",
    "        mask_drugs=True,\n",
    "        delete_temporary_variables=True,\n",
    "        split_sequence=True,\n",
    "        drop_duplicates=True,\n",
    "        converted_codes=False,\n",
    "        convert_icd_to_phewas=True,\n",
    "        convert_rxcui_to_atc=True,\n",
    "        keep_min_unmasked=1,\n",
    "        max_masked_tokens=20,\n",
    "        masked_lm_prob=0.15,\n",
    "        truncate='right',\n",
    "        index_date=None,\n",
    "        had_plos=None,\n",
    "        endpoint_labels=patient_data.get('endpoint_labels', None),\n",
    "        dynamic_masking=False,\n",
    "        min_observations=5,\n",
    "        age_usage='year',\n",
    "        use_cls=True,\n",
    "        use_sep=True,\n",
    "        valid_patient=True,\n",
    "        num_visits=None,\n",
    "        combined_length=None,\n",
    "        unpadded_length=None\n",
    "    )\n",
    "    patient_objs.append(patient_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe32d86",
   "metadata": {},
   "source": [
    "## 9. Creating and Saving the PatientDataset\n",
    "\n",
    "The `PatientDataset` class batches multiple `Patient` objects and prepares them for model training. It handles masking, batching, and can save the dataset to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8175db9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './demo_patient_dataset.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Save the dataset to disk for use in pretraining\u001b[39;00m\n\u001b[0;32m     20\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./demo_patient_dataset.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mpatient_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatientDataset saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You can now use this file for pretraining.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\E648736\\OneDrive - UCB\\Desktop\\Projects\\ExMed-BERT-main\\./ExMed-BERT-main\\exmed_bert\\data\\dataset.py:504\u001b[0m, in \u001b[0;36mPatientDataset.save_dataset\u001b[1;34m(self, path, with_patients, do_copy)\u001b[0m\n\u001b[0;32m    502\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mloaded_to_ram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    503\u001b[0m dataset\u001b[38;5;241m.\u001b[39mendpoint_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\E648736\\AppData\\Local\\anaconda3\\envs\\exmed-bert\\lib\\site-packages\\torch\\serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32mc:\\Users\\E648736\\AppData\\Local\\anaconda3\\envs\\exmed-bert\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\E648736\\AppData\\Local\\anaconda3\\envs\\exmed-bert\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './demo_patient_dataset.pt'"
     ]
    }
   ],
   "source": [
    "patient_dataset = PatientDataset(\n",
    "    code_embed=code_dict,\n",
    "    age_embed=age_dict,\n",
    "    sex_embed=sex_dict,\n",
    "    state_embed=state_dict,\n",
    "    endpoint_dict=endpoint_dict,\n",
    "    patient_paths=None,\n",
    "    max_length=16,\n",
    "    do_eval=True,\n",
    "    mask_substances=True,\n",
    "    dataset_path=None,\n",
    "    patients=patient_objs,\n",
    "    dynamic_masking=False,\n",
    "    min_unmasked=1,\n",
    "    max_masked=20,\n",
    "    masked_lm_prob=0.15\n",
    ")\n",
    "\n",
    "# Save the dataset to disk for use in pretraining\n",
    "output_path = './demo_patient_dataset.pt'\n",
    "patient_dataset.save_dataset(output_path)\n",
    "print(f'PatientDataset saved to {output_path}. You can now use this file for pretraining.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ba9e2",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "- We defined encoding dictionaries for all categorical data.\n",
    "- We created example patients and encoded their data.\n",
    "- We processed and masked the data for BERT-style pretraining.\n",
    "- We batched patients into a dataset and saved it for model training.\n",
    "\n",
    "This workflow ensures that all patient data is consistently and efficiently prepared for use in ExMed-BERT or similar models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exmed-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
